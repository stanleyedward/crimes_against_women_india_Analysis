{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "VpIVSUyR1aNT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7YiKVXAm12c0"
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"dataset/dataset0121.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 659
    },
    "id": "BxjWKyxV2OWJ",
    "outputId": "58d1c310-2fec-41ee-e148-58a3f517e054"
   },
   "outputs": [],
   "source": [
    "\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "7FeGIk832Pm4",
    "outputId": "b400ba23-a6d3-4765-c096-3c5066f30f6f"
   },
   "outputs": [],
   "source": [
    "df1.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_yp0X9y2dcw",
    "outputId": "3e9eb7b6-ed93-4d50-f0e9-de8356012aa9"
   },
   "outputs": [],
   "source": [
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wRiM8W_V4nfh",
    "outputId": "ecbe7144-9995-4b0c-dfd5-c44a03a0dc7b"
   },
   "outputs": [],
   "source": [
    "df1['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kAWD4oXJ44Ob"
   },
   "outputs": [],
   "source": [
    "df1.loc[df1['State'] == 'A&N Islands', 'State'] = 'A & N ISLANDS'\n",
    "df1.loc[df1['State'] == 'D&N Haveli', 'State'] = 'D & N HAVELI'\n",
    "df1.loc[df1['State'] == 'Delhi UT', 'State'] = 'DELHI'\n",
    "\n",
    "df1['State'] = pd.Series(str.upper(i) for i in df1['State'])\n",
    "# df1['DISTRICT'] = pd.Series(str.upper(i) for i in df1['DISTRICT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTx6kTJv5HHj",
    "outputId": "f7552481-5651-4fdd-ba1e-4f8412e74fd7"
   },
   "outputs": [],
   "source": [
    "df1['State'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_and_year_crimes = df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "egwYUBoZ_AR-",
    "outputId": "d97edef9-06da-45aa-9f26-6f7e7805d5cb"
   },
   "outputs": [],
   "source": [
    "state_all_crimes_1 = df1.groupby('State').sum()\n",
    "state_all_crimes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_and_year_crimes = state_all_crimes_1\n",
    "state_all_crimes_1.drop('Year',axis=1,inplace=True)\n",
    "state_all_crimes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list_1= list(state_all_crimes_1)                                         \n",
    "state_all_crimes_1[col_list_1] = state_all_crimes_1[col_list_1].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Sum across rows\n",
    "state_all_crimes_1['Total'] = state_all_crimes_1[col_list_1].sum(axis=1)\n",
    "\n",
    "all_crimes_1 = state_all_crimes_1\n",
    "\n",
    "all_crimes_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "F7HZIb4pAVJe",
    "outputId": "29f32f6e-9fc2-4c11-9268-2086d30f1272"
   },
   "outputs": [],
   "source": [
    "total_df=state_all_crimes_1.sum(axis=0).reset_index()\n",
    "tf=pd.DataFrame(total_df)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "7SUe9wwU3uOP",
    "outputId": "a84e1168-b249-45fa-c765-73fdc319327c"
   },
   "outputs": [],
   "source": [
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "bEsyQM-OA0qi",
    "outputId": "960a3421-de01-4f1e-f95b-5ecde31eb0af"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "sorted_df = state_all_crimes_1.sort_values('Total',ascending=False)\n",
    "fig = px.bar( x=tf[\"index\"],y=tf[0], color=tf[0], \n",
    "             labels={'x': \"Crimes\", 'y': \"Count\"}, title=\"Total Cases\", \n",
    "             color_continuous_scale='Viridis')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "4Hx4AUE-EdbP"
   },
   "outputs": [],
   "source": [
    "# tf=tf.drop([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "BXtoVKLQEjRu"
   },
   "outputs": [],
   "source": [
    "# tf=tf.drop([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "id": "ed74iGKttOYs",
    "outputId": "38aaca9e-f2f2-4fee-9f2a-8e1f270a6c4a"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "sorted_df = state_all_crimes_1.sort_values('Total',ascending=False)\n",
    "total_df=sorted_df.sum(axis=0).reset_index()\n",
    "total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 671
    },
    "id": "n_oPR4jP5K_f",
    "outputId": "27d61a05-d9b7-4d70-c969-276f612bf24a"
   },
   "outputs": [],
   "source": [
    "state_all_crimes = df1.groupby('Year').sum()\n",
    "state_all_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(state_all_crimes)\n",
    "state_all_crimes[col_list] = state_all_crimes[col_list].apply(pd.to_numeric, errors='coerce')\n",
    "state_all_crimes['Total'] = state_all_crimes[col_list].sum(axis=1)\n",
    "all_crimes = state_all_crimes.drop(columns=['State'])\n",
    "all_crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_crimes.loc[2011, 'Assault against women'] = np.nan\n",
    "all_crimes['Assault against women'] = all_crimes['Assault against women'].astype(float)\n",
    "all_crimes['Assault against women'].interpolate(inplace=True)\n",
    "all_crimes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 567
    },
    "id": "0GeSIowP8x9x",
    "outputId": "19de2de4-0341-4c16-b257-6d6c214beba5"
   },
   "outputs": [],
   "source": [
    "total_df_1=all_crimes.reset_index()\n",
    "tf_1=pd.DataFrame(total_df_1)\n",
    "tf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = tf_1[[\"Year\"]]  \n",
    "y = tf_1[[\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "        \"Assault against women\", \n",
    "        \"Assault against modesty of women\", \"Domestic violence\", \n",
    "        \"Women Trafficking\", \"Total\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = linear_model.LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "y_train_pred = model.predict(x_train)\n",
    "y_test_pred = model.predict(x_test)\n",
    "    \n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))\n",
    "\n",
    "for i, crime_type in enumerate(y.columns):\n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax[row, col].scatter(x_train, y_train[crime_type], color='blue', label='Actual (Train)', alpha=0.6)\n",
    "    ax[row, col].scatter(x_test, y_test[crime_type], color='green', label='Actual (Test)', alpha=0.6)\n",
    "    ax[row, col].plot(x_train, y_train_pred[:, i], color='red', linewidth=2, label='Predicted (Train)')\n",
    "    ax[row, col].plot(x_test, y_test_pred[:, i], color='orange', linewidth=2, label='Predicted (Test)')\n",
    "    ax[row, col].set_title(crime_type)\n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "plt.tight_layout()  # Adjust subplots to fit into figure area\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qujyFcxoRxbf",
    "outputId": "b1b65305-4039-433a-d29e-f7e6528612bf"
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtqBUGlLSH63",
    "outputId": "ec4ea4aa-5bb7-4f4f-9b98-bddfc1bec4c5"
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "metrics = {\n",
    "    'Crime Category': [],\n",
    "    'MAE (Train)': [],\n",
    "    'MSE (Train)': [],\n",
    "    'RMSE (Train)': [],\n",
    "    'R^2 (Train)': [],\n",
    "    'MAE (Test)': [],\n",
    "    'MSE (Test)': [],\n",
    "    'RMSE (Test)': [],\n",
    "    'R^2 (Test)': []\n",
    "}\n",
    "\n",
    "for i, crime_type in enumerate(y.columns):\n",
    "    metrics['Crime Category'].append(crime_type)\n",
    "    \n",
    "    mae_train = mean_absolute_error(y_train[crime_type], y_train_pred[:, i])\n",
    "    mse_train = mean_squared_error(y_train[crime_type], y_train_pred[:, i])\n",
    "    rmse_train = np.sqrt(mse_train) \n",
    "    r2_train = r2_score(y_train[crime_type], y_train_pred[:, i])\n",
    "    \n",
    "    mae_test = mean_absolute_error(y_test[crime_type], y_test_pred[:, i])\n",
    "    mse_test = mean_squared_error(y_test[crime_type], y_test_pred[:, i])\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "    r2_test = r2_score(y_test[crime_type], y_test_pred[:, i])\n",
    "    \n",
    "    metrics['MAE (Train)'].append(mae_train)\n",
    "    metrics['MSE (Train)'].append(mse_train)\n",
    "    metrics['RMSE (Train)'].append(rmse_train)\n",
    "    metrics['R^2 (Train)'].append(r2_train)\n",
    "    metrics['MAE (Test)'].append(mae_test)\n",
    "    metrics['MSE (Test)'].append(mse_test)\n",
    "    metrics['RMSE (Test)'].append(rmse_test)\n",
    "    metrics['R^2 (Test)'].append(r2_test)\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics)\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical test using randomfoest regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred_rf = rf_model.predict(x_train)\n",
    "y_test_pred_rf = rf_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_train_lr = mean_squared_error(y_train, y_train_pred)\n",
    "mse_test_lr = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "mse_train_rf = mean_squared_error(y_train, y_train_pred_rf)\n",
    "mse_test_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "\n",
    "print(\"Linear Regression MSE on Train Data: \", mse_train_lr/10e7,\"e+07\")\n",
    "print(\"Linear Regression MSE on Test Data: \", mse_test_lr/10e7,\"e+07\")\n",
    "print(\"Random Forest MSE on Train Data: \", mse_train_rf/10e7,\"e+07\")\n",
    "print(\"Random Forest MSE on Test Data: \", mse_test_rf/10e7,\"e+07\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, target_name in enumerate(y.columns):\n",
    "    y_test_pred_target = y_test_pred[:, i]\n",
    "    y_test_pred_rf_target = y_test_pred_rf[:, i]\n",
    "\n",
    "    t_stat, p_value = ttest_rel(y_test_pred_target, y_test_pred_rf_target)\n",
    "\n",
    "    print(f\"Results for target: {target_name}\")\n",
    "    print(f\"t-statistic: {t_stat}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "\n",
    "    if p_value < 0.05:\n",
    "        print(\"The difference in model performance is statistically significant.\\n\")\n",
    "    else:\n",
    "        print(\"The difference in model performance is not statistically significant.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "mse_lr_list = []\n",
    "mse_rf_list = []\n",
    "\n",
    "for train_index, test_index in loo.split(x):\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    y_test_pred_lr = lr_model.predict(x_test)\n",
    "    mse_lr = mean_squared_error(y_test, y_test_pred_lr)\n",
    "    mse_lr_list.append(mse_lr)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    y_test_pred_rf = rf_model.predict(x_test)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "    mse_rf_list.append(mse_rf)\n",
    "\n",
    "avg_mse_lr = np.mean(mse_lr_list)\n",
    "avg_mse_rf = np.mean(mse_rf_list)\n",
    "\n",
    "print(f\"Average MSE for Linear Regression (LOOCV): {avg_mse_lr/10e7}e+07\")\n",
    "print(f\"Average MSE for Random Forest (LOOCV): {avg_mse_rf/10e7}e+07\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "mse_lr_list = []\n",
    "mse_rf_list = []\n",
    "\n",
    "for train_index, test_index in kf.split(x):\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(x_train, y_train)\n",
    "    y_test_pred_lr = lr_model.predict(x_test)\n",
    "    mse_lr = mean_squared_error(y_test, y_test_pred_lr)\n",
    "    mse_lr_list.append(mse_lr)\n",
    "    \n",
    "    rf_model = RandomForestRegressor(random_state=42)\n",
    "    rf_model.fit(x_train, y_train)\n",
    "    y_test_pred_rf = rf_model.predict(x_test)\n",
    "    mse_rf = mean_squared_error(y_test, y_test_pred_rf)\n",
    "    mse_rf_list.append(mse_rf)\n",
    "\n",
    "avg_mse_lr = np.mean(mse_lr_list)\n",
    "avg_mse_rf = np.mean(mse_rf_list)\n",
    "\n",
    "print(f\"Average MSE for Linear Regression: {avg_mse_lr/10e7}e+07\")\n",
    "print(f\"Average MSE for Random Forest: {avg_mse_rf/10e7}e+07\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA testing till 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "            \"Assault against women\", \n",
    "            \"Assault against modesty of women\", \"Domestic violence\", \n",
    "            \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "x = tf_1[[\"Year\"]]  \n",
    "y = tf_1[crime_types]  \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))              \n",
    "\n",
    "for i, crime_type in enumerate(crime_types):\n",
    "    row = i // 4  \n",
    "    col = i % 4  \n",
    "    \n",
    "\n",
    "    y_train_crime = y_train[crime_type]\n",
    "    y_test_crime = y_test[crime_type]\n",
    "    \n",
    "    model = ARIMA(y_train_crime, order=(1, 1, 1))  \n",
    "    model_fit = model.fit()\n",
    "\n",
    "\n",
    "    y_train_pred = model_fit.fittedvalues\n",
    "    y_test_pred = model_fit.forecast(steps=len(y_test_crime))\n",
    "\n",
    "    ax[row, col].scatter(x_train, y_train_crime, color='blue', label='Actual (Train)', alpha=0.6)\n",
    "    ax[row, col].scatter(x_test, y_test_crime, color='green', label='Actual (Test)', alpha=0.6)\n",
    "    ax[row, col].plot(x_train, y_train_pred, color='red', linewidth=2, label='Predicted (Train)')\n",
    "    ax[row, col].plot(x_test, y_test_pred, color='orange', linewidth=2, label='Predicted (Test)')\n",
    "    \n",
    "    ax[row, col].set_title(crime_type)\n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV on ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming tf_1 is your dataframe\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\",\n",
    "               \"Assault against women\", \"Assault against modesty of women\",\n",
    "               \"Domestic violence\", \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "def time_series_cv(data, n_splits=5):\n",
    "    n = len(data)\n",
    "    k = n // n_splits\n",
    "    for i in range(n_splits):\n",
    "        train = data.iloc[:n - (i+1)*k]\n",
    "        test = data.iloc[n - (i+1)*k:n - i*k]\n",
    "        yield train, test\n",
    "\n",
    "mse_scores = {crime_type: [] for crime_type in crime_types}\n",
    "\n",
    "for crime_type in crime_types:\n",
    "    y = tf_1[[\"Year\", crime_type]].set_index(\"Year\")\n",
    "    \n",
    "    for train, test in time_series_cv(y):\n",
    "        model = ARIMA(train, order=(1, 1, 1))\n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        forecast = model_fit.forecast(steps=len(test))\n",
    "        mse = mean_squared_error(test, forecast)\n",
    "        mse_scores[crime_type].append(mse/10e7)\n",
    "\n",
    "print(\"Average MSE scores:\")\n",
    "for crime_type, scores in mse_scores.items():\n",
    "    avg_mse = np.mean(scores)\n",
    "    print(f\"{crime_type}: {avg_mse:.2f}e+07\")\n",
    "\n",
    "print(\"\\nMSE scores for each fold:\")\n",
    "for crime_type, scores in mse_scores.items():\n",
    "    print(f\"\\n{crime_type}:\")\n",
    "    for i, score in enumerate(scores, 1):\n",
    "        print(f\"  Fold {i}: {score:.2f}e+07\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMA till 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "               \"Assault against women\", \n",
    "               \"Assault against modesty of women\", \"Domestic violence\", \n",
    "               \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))\n",
    "\n",
    "\n",
    "for i, crime_type in enumerate(crime_types):\n",
    "    row = i // 4  \n",
    "    col = i % 4  \n",
    "    \n",
    "    y_full = tf_1[crime_type]\n",
    "\n",
    "    model = ARIMA(y_full, order=(1, 1, 1))  \n",
    "    model_fit = model.fit()\n",
    "\n",
    "    forecast_steps = 3\n",
    "    y_forecast = model_fit.forecast(steps=forecast_steps)\n",
    "\n",
    "    future_years = pd.DataFrame({\n",
    "        'Year': [2022, 2023, 2024],\n",
    "        crime_type: y_forecast\n",
    "    }).set_index('Year')\n",
    "\n",
    "    full_data = pd.concat([tf_1[[crime_type]].set_index(tf_1['Year']), future_years])\n",
    "\n",
    "    ax[row, col].plot(full_data.index, full_data[crime_type], marker='o', label='Historical Data', color='blue')\n",
    "    ax[row, col].plot(future_years.index, future_years[crime_type], marker='o', color='red', label='Forecasted Data')\n",
    "\n",
    "    ax[row, col].set_title(crime_type)              \n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "x = tf_1[[\"Year\"]]  \n",
    "y = tf_1[[\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "           \"Assault against women\", \n",
    "           \"Assault against modesty of women\", \"Domestic violence\", \n",
    "           \"Women Trafficking\", \"Total\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))\n",
    "\n",
    "for i, crime_type in enumerate(y.columns):\n",
    "    scaler_x = StandardScaler()\n",
    "    x_train_scaled = scaler_x.fit_transform(x_train)\n",
    "    x_test_scaled = scaler_x.transform(x_test)\n",
    "    \n",
    "    scaler_y = StandardScaler()\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train[[crime_type]])\n",
    "    \n",
    "    model = SVR(kernel='rbf')\n",
    "    model.fit(x_train_scaled, y_train_scaled.ravel())  # Use ravel to flatten y_train\n",
    "\n",
    "    # Make predictions\n",
    "    y_train_pred_scaled = model.predict(x_train_scaled)\n",
    "    y_test_pred_scaled = model.predict(x_test_scaled)\n",
    "    \n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled.reshape(-1, 1))\n",
    "    \n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax[row, col].scatter(x_train, y_train[crime_type], color='blue', label='Actual (Train)', alpha=0.6)\n",
    "    ax[row, col].scatter(x_test, y_test[crime_type], color='green', label='Actual (Test)', alpha=0.6)\n",
    "    ax[row, col].plot(x_train, y_train_pred, color='red', linewidth=2, label='Predicted (Train)')\n",
    "    ax[row, col].plot(x_test, y_test_pred, color='orange', linewidth=2, label='Predicted (Test)')\n",
    "    ax[row, col].set_title(crime_type)\n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KN Regression       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "x = tf_1[[\"Year\"]]  \n",
    "y = tf_1[[\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "           \"Assault against women\", \n",
    "           \"Assault against modesty of women\", \"Domestic violence\", \n",
    "           \"Women Trafficking\", \"Total\"]]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))\n",
    "\n",
    "for i, crime_type in enumerate(y.columns):\n",
    "    scaler_x = StandardScaler()\n",
    "    x_train_scaled = scaler_x.fit_transform(x_train)\n",
    "    x_test_scaled = scaler_x.transform(x_test)\n",
    "    \n",
    "    scaler_y = StandardScaler()\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train[[crime_type]])\n",
    "    \n",
    "    model = KNeighborsRegressor(n_neighbors=5) \n",
    "    model.fit(x_train_scaled, y_train_scaled.ravel())  \n",
    "\n",
    "    y_train_pred_scaled = model.predict(x_train_scaled)\n",
    "    y_test_pred_scaled = model.predict(x_test_scaled)\n",
    "    \n",
    "    y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled.reshape(-1, 1))\n",
    "    y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled.reshape(-1, 1))\n",
    "                \n",
    "    row = i // 4\n",
    "    col = i % 4\n",
    "    ax[row, col].scatter(x_train, y_train[crime_type], color='blue', label='Actual (Train)', alpha=0.6)\n",
    "    ax[row, col].scatter(x_test, y_test[crime_type], color='green', label='Actual (Test)', alpha=0.6)\n",
    "    ax[row, col].plot(x_train, y_train_pred, color='red', linewidth=2, label='Predicted (Train)')\n",
    "    ax[row, col].plot(x_test, y_test_pred, color='orange', linewidth=2, label='Predicted (Test)')\n",
    "    ax[row, col].set_title(crime_type)\n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of crime types\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "               \"Assault against women\", \n",
    "               \"Assault against modesty of women\", \"Domestic violence\", \n",
    "               \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "# Extract features and targets\n",
    "x = tf_1[[\"Year\"]]  \n",
    "y = tf_1[crime_types]  \n",
    "\n",
    "# Split data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))              \n",
    "\n",
    "for i, crime_type in enumerate(crime_types):\n",
    "    row = i // 4  \n",
    "    col = i % 4  \n",
    "\n",
    "    # Get the training and testing data for the current crime type\n",
    "    y_train_crime = y_train[crime_type]\n",
    "    y_test_crime = y_test[crime_type]\n",
    "    \n",
    "    # Train Decision Tree Regressor model\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    model.fit(x_train, y_train_crime)\n",
    "\n",
    "    # Predict on training and testing sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Plot the actual vs predicted values\n",
    "    ax[row, col].scatter(x_train, y_train_crime, color='blue', label='Actual (Train)', alpha=0.6)\n",
    "    ax[row, col].scatter(x_test, y_test_crime, color='green', label='Actual (Test)', alpha=0.6)\n",
    "    ax[row, col].plot(x_train, y_train_pred, color='red', linewidth=2, label='Predicted (Train)')\n",
    "    ax[row, col].plot(x_test, y_test_pred, color='orange', linewidth=2, label='Predicted (Test)')\n",
    "    \n",
    "    # Set plot titles and labels\n",
    "    ax[row, col].set_title(crime_type)\n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# List of crime types\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "               \"Assault against women\", \n",
    "               \"Assault against modesty of women\", \"Domestic violence\", \n",
    "               \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "# Extract features and targets\n",
    "x = tf_1[[\"Year\"]]  \n",
    "y = tf_1[crime_types]\n",
    "\n",
    "# Set up K-Fold Cross Validation (e.g., 5 folds)\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "# Dictionary to store average MSE for each crime type\n",
    "avg_mse = {}\n",
    "\n",
    "# Loop through each crime type\n",
    "for i, crime_type in enumerate(crime_types):\n",
    "    row = i // 4  \n",
    "    col = i % 4  \n",
    "\n",
    "    # Get the data for the current crime type\n",
    "    y_crime = y[crime_type]\n",
    "\n",
    "    # Initialize Decision Tree Regressor model\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "    # Perform K-Fold Cross-Validation\n",
    "    y_pred = cross_val_predict(model, x, y_crime, cv=kf)\n",
    "\n",
    "    # Calculate MSE for each fold\n",
    "    mse = mean_squared_error(y_crime, y_pred)\n",
    "    avg_mse[crime_type] = mse\n",
    "    \n",
    "# Print the average MSE for each crime type\n",
    "for crime_type, mse_value in avg_mse.items():\n",
    "    print(f\"Average MSE for {crime_type}: {mse_value/10e7:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees with lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature engineering for time series\n",
    "def create_features(df, crime_types, lags=3, rolling_window=3):\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # Create lag features\n",
    "    for crime_type in crime_types:\n",
    "        for lag in range(1, lags+1):\n",
    "            df_features[f\"{crime_type}_lag_{lag}\"] = df[crime_type].shift(lag)\n",
    "\n",
    "    # Create rolling statistics features (rolling mean and std)\n",
    "    for crime_type in crime_types:\n",
    "        df_features[f\"{crime_type}_rolling_mean\"] = df[crime_type].rolling(window=rolling_window).mean()\n",
    "        df_features[f\"{crime_type}_rolling_std\"] = df[crime_type].rolling(window=rolling_window).std()\n",
    "    \n",
    "    # Time-based features\n",
    "    df_features['Year'] = df['Year']\n",
    "    df_features['Year_diff'] = df['Year'].diff()\n",
    "\n",
    "    # Drop any rows with NaN values created by lagging/rolling\n",
    "    df_features = df_features.dropna().reset_index(drop=True)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Create Fourier features for seasonality (e.g., yearly seasonality)\n",
    "def create_fourier_features(df, period, order):\n",
    "    t = np.arange(len(df))\n",
    "    for i in range(1, order + 1):\n",
    "        df[f'sin_{i}'] = np.sin(2 * np.pi * i * t / period)\n",
    "        df[f'cos_{i}'] = np.cos(2 * np.pi * i * t / period)\n",
    "    return df\n",
    "\n",
    "# Assuming 'tf_1' is your original DataFrame\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "               \"Assault against women\", \n",
    "               \"Assault against modesty of women\", \"Domestic violence\", \n",
    "               \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "# Create lagged and rolling features\n",
    "tf_1_features = create_features(tf_1, crime_types)\n",
    "\n",
    "# Add Fourier terms for yearly seasonality (period = 1 year, order = 2 or 3)\n",
    "tf_1_features = create_fourier_features(tf_1_features, period=21, order=3)  # Period = 21 because it's yearly data from 2001-2021\n",
    "\n",
    "# Separate features (x) and targets (y)\n",
    "x = tf_1_features.drop(columns=crime_types)  # All columns except crime types are features\n",
    "y = tf_1_features[crime_types]  # Crime types as targets\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))              \n",
    "\n",
    "for i, crime_type in enumerate(crime_types):\n",
    "    row = i // 4  \n",
    "    col = i % 4  \n",
    "\n",
    "    # Get the training and testing data for the current crime type\n",
    "    y_train_crime = y_train[crime_type]\n",
    "    y_test_crime = y_test[crime_type]\n",
    "\n",
    "    # Train Decision Tree Regressor model\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    model.fit(x_train, y_train_crime)\n",
    "\n",
    "    # Predict on training and testing sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Plot the actual vs predicted values\n",
    "    ax[row, col].scatter(x_train['Year'], y_train_crime, color='blue', label='Actual (Train)', alpha=0.6)\n",
    "    ax[row, col].scatter(x_test['Year'], y_test_crime, color='green', label='Actual (Test)', alpha=0.6)\n",
    "    ax[row, col].plot(x_train['Year'], y_train_pred, color='red', linewidth=2, label='Predicted (Train)')\n",
    "    ax[row, col].plot(x_test['Year'], y_test_pred, color='orange', linewidth=2, label='Predicted (Test)')\n",
    "    \n",
    "    # Set plot titles and labels\n",
    "    ax[row, col].set_title(crime_type)\n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARIMAX testing till 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of crime types\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "               \"Assault against women\", \"Assault against modesty of women\", \n",
    "               \"Domestic violence\", \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "# Extract year as the feature\n",
    "x = tf_1[[\"Year\"]]\n",
    "\n",
    "# Target variable (the crime data)\n",
    "y = tf_1[crime_types]\n",
    "\n",
    "# Let's assume \"Total\" crime will be used as the exogenous variable (can be adjusted as needed)\n",
    "exogenous_variables = tf_1[[\"Rape\"]]\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "exog_train, exog_test = train_test_split(exogenous_variables, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))\n",
    "\n",
    "# Loop through each crime type and fit the ARIMAX model\n",
    "for i, crime_type in enumerate(crime_types):\n",
    "    row = i // 4  # Determines the row for the subplot\n",
    "    col = i % 4   # Determines the column for the subplot\n",
    "    \n",
    "    # Train and test data for the specific crime type\n",
    "    y_train_crime = y_train[crime_type]\n",
    "    y_test_crime = y_test[crime_type]\n",
    "\n",
    "    # Fit ARIMAX model with the 'Total' crime as an exogenous variable\n",
    "    model = ARIMA(y_train_crime, order=(1, 1, 1), exog=exog_train)  # ARIMAX with exogenous variables\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = model_fit.fittedvalues\n",
    "    y_test_pred = model_fit.forecast(steps=len(y_test_crime), exog=exog_test)\n",
    "\n",
    "    # Plotting the results\n",
    "    ax[row, col].scatter(x_train, y_train_crime, color='blue', label='Actual (Train)', alpha=0.6)\n",
    "    ax[row, col].scatter(x_test, y_test_crime, color='green', label='Actual (Test)', alpha=0.6)\n",
    "    ax[row, col].plot(x_train, y_train_pred, color='red', linewidth=2, label='Predicted (Train)')\n",
    "    ax[row, col].plot(x_test, y_test_pred, color='orange', linewidth=2, label='Predicted (Test)')\n",
    "    \n",
    "    # Setting titles and labels\n",
    "    ax[row, col].set_title(crime_type)\n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "# List of crime types\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "               \"Assault against women\", \"Assault against modesty of women\", \n",
    "               \"Domestic violence\", \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "# Extract year as the feature\n",
    "x = tf_1[[\"Year\"]]\n",
    "\n",
    "# Target variable (the crime data)\n",
    "y = tf_1[crime_types]\n",
    "\n",
    "# Let's assume \"Rape\" will be used as the exogenous variable (can be adjusted as needed)\n",
    "exogenous_variables = tf_1[[\"Total\"]]\n",
    "\n",
    "# Set up TimeSeriesSplit for K-Fold cross-validation (e.g., 5 folds)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Initialize a dictionary to store the average MSE for each crime type\n",
    "avg_mse = {crime_type: [] for crime_type in crime_types}\n",
    "\n",
    "# Perform TimeSeries K-Fold Cross Validation\n",
    "for crime_type in crime_types:\n",
    "    mse_list = []\n",
    "    \n",
    "    # Iterate through the splits\n",
    "    for train_index, test_index in tscv.split(x):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        y_train_fold, y_test_fold = y[crime_type].iloc[train_index], y[crime_type].iloc[test_index]\n",
    "        exog_train_fold, exog_test_fold = exogenous_variables.iloc[train_index], exogenous_variables.iloc[test_index]\n",
    "        \n",
    "        # Fit ARIMAX model with the exogenous variable\n",
    "        model = ARIMA(y_train_fold, order=(1, 1, 1), exog=exog_train_fold)\n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        # Predict on the test set of the current fold\n",
    "        y_test_pred_fold = model_fit.forecast(steps=len(y_test_fold), exog=exog_test_fold)\n",
    "        \n",
    "        # Compute MSE for the current fold\n",
    "        mse = mean_squared_error(y_test_fold, y_test_pred_fold)\n",
    "        mse_list.append(mse)\n",
    "    \n",
    "    # Store the average MSE for the current crime type\n",
    "    avg_mse[crime_type] = np.mean(mse_list)\n",
    "\n",
    "# Print the average MSE for each crime type\n",
    "for crime_type, mse_value in avg_mse.items():   \n",
    "    print(f\"Average MSE for {crime_type}: {mse_value/10e7:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = states_and_year_crimes\n",
    "\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "            \"Assault against women\", \n",
    "            \"Assault against modesty of women\", \"Domestic violence\", \n",
    "            \"Women Trafficking\"]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# One-hot encode the State column\n",
    "onehotencoder = OneHotEncoder()\n",
    "state_encoded = onehotencoder.fit_transform(df1[['State']]).toarray()\n",
    "\n",
    "# Standardize the crime data (excluding 'Year' column)\n",
    "scaler = StandardScaler()\n",
    "crime_data = scaler.fit_transform(df1[crime_types])\n",
    "\n",
    "# Concatenate one-hot encoded states, year, and scaled crime data\n",
    "X = np.concatenate([state_encoded, df1[['Year']].values, crime_data], axis=1)\n",
    "y = df1[crime_types]  # If you're predicting crime rates, use this as target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest Regressor for each crime type\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate error (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error: \", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define high-risk states based on a threshold\n",
    "df1['High_Risk'] = (df1['Rape'] > df1['Rape'].mean()) & (df1['Domestic violence'] > df1['Domestic violence'].mean())\n",
    "\n",
    "# Perform train-test split and train a classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "y_classification = df1['High_Risk'].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_classification, test_size=0.2, random_state=42)\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Check accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Iterate through each state and fit an ARIMA model\n",
    "states = df1['State'].unique()\n",
    "for state in states:\n",
    "    state_data = df1[df1['State'] == state]\n",
    "    for crime in crime_types:\n",
    "        model = ARIMA(state_data[crime], order=(1, 1, 1))\n",
    "        model_fit = model.fit()\n",
    "        forecast = model_fit.forecast(steps=5)  # Forecasting for next 5 years\n",
    "        print(f\"Forecast for {crime} in {state}: \", forecast)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df1[crime_types].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation between Crime Types')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# List of crime types\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "               \"Assault against women\", \n",
    "               \"Assault against modesty of women\", \"Domestic violence\", \n",
    "               \"Women Trafficking\"]\n",
    "\n",
    "# Convert \"Year\" column to datetime\n",
    "df1['Year'] = pd.to_datetime(df1['Year'], format='%Y')\n",
    "\n",
    "# Get unique states\n",
    "states = df1['State'].unique()\n",
    "\n",
    "# Iterate over each state\n",
    "for state in states:\n",
    "    state_data = df1[df1[\"State\"] == state]  # Filter data by state\n",
    "\n",
    "    # Use 'Year' as index for time series modeling\n",
    "    state_data = state_data.set_index('Year')\n",
    "    \n",
    "    # Plot setup\n",
    "    fig, ax = plt.subplots(2, 4, figsize=(15, 10))  \n",
    "    fig.suptitle(f\"Crime Analysis for {state}\", fontsize=16)\n",
    "\n",
    "    for i, crime_type in enumerate(crime_types):\n",
    "        row = i // 4  \n",
    "        col = i % 4  \n",
    "\n",
    "        # Train-test split based on the year\n",
    "        y = state_data[crime_type]\n",
    "        y_train, y_test = y[:int(len(y) * 0.8)], y[int(len(y) * 0.8):]\n",
    "\n",
    "        # Fit ARIMA model\n",
    "        model = ARIMA(y_train, order=(1, 1, 1))  \n",
    "        model_fit = model.fit()\n",
    "\n",
    "        # Forecast\n",
    "        y_train_pred = model_fit.fittedvalues\n",
    "        y_test_pred = model_fit.forecast(steps=len(y_test))\n",
    "\n",
    "        # Plot actual vs predicted values\n",
    "        ax[row, col].scatter(y_train.index, y_train, color='blue', label='Actual (Train)', alpha=0.6)\n",
    "        ax[row, col].scatter(y_test.index, y_test, color='green', label='Actual (Test)', alpha=0.6)\n",
    "        ax[row, col].plot(y_train.index, y_train_pred, color='red', linewidth=2, label='Predicted (Train)')\n",
    "        ax[row, col].plot(y_test.index, y_test_pred, color='orange', linewidth=2, label='Predicted (Test)')\n",
    "\n",
    "        ax[row, col].set_title(crime_type)\n",
    "        ax[row, col].set_xlabel('Year')\n",
    "        ax[row, col].set_ylabel('Cases')\n",
    "        ax[row, col].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.88)  # Adjust for title space\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kfold on decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature engineering for time series\n",
    "def create_features(df, crime_types, lags=3, rolling_window=3):\n",
    "    df_features = df.copy()\n",
    "    \n",
    "    # Create lag features\n",
    "    for crime_type in crime_types:\n",
    "        for lag in range(1, lags+1):\n",
    "            df_features[f\"{crime_type}_lag_{lag}\"] = df[crime_type].shift(lag)\n",
    "\n",
    "    # Create rolling statistics features (rolling mean and std)\n",
    "    for crime_type in crime_types:\n",
    "        df_features[f\"{crime_type}_rolling_mean\"] = df[crime_type].rolling(window=rolling_window).mean()\n",
    "        df_features[f\"{crime_type}_rolling_std\"] = df[crime_type].rolling(window=rolling_window).std()\n",
    "    \n",
    "    # Time-based features\n",
    "    df_features['Year'] = df['Year']\n",
    "    df_features['Year_diff'] = df['Year'].diff()\n",
    "\n",
    "    # Drop any rows with NaN values created by lagging/rolling\n",
    "    df_features = df_features.dropna().reset_index(drop=True)\n",
    "    \n",
    "    return df_features\n",
    "\n",
    "# Create Fourier features for seasonality (e.g., yearly seasonality)\n",
    "def create_fourier_features(df, period, order):\n",
    "    t = np.arange(len(df))\n",
    "    for i in range(1, order + 1):\n",
    "        df[f'sin_{i}'] = np.sin(2 * np.pi * i * t / period)\n",
    "        df[f'cos_{i}'] = np.cos(2 * np.pi * i * t / period)\n",
    "    return df\n",
    "\n",
    "# Assuming 'tf_1' is your original DataFrame\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "               \"Assault against women\", \n",
    "               \"Assault against modesty of women\", \"Domestic violence\", \n",
    "               \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "# Create lagged and rolling features\n",
    "tf_1_features = create_features(tf_1, crime_types)\n",
    "\n",
    "# Add Fourier terms for yearly seasonality (period = 1 year, order = 2 or 3)\n",
    "tf_1_features = create_fourier_features(tf_1_features, period=21, order=3)  # Period = 21 because it's yearly data from 2001-2021\n",
    "\n",
    "# Separate features (x) and targets (y)\n",
    "x = tf_1_features.drop(columns=crime_types)  # All columns except crime types are features\n",
    "y = tf_1_features[crime_types]  # Crime types as targets\n",
    "\n",
    "# Train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=False)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(2, 4, figsize=(15, 10))              \n",
    "\n",
    "for i, crime_type in enumerate(crime_types):\n",
    "    row = i // 4  \n",
    "    col = i % 4  \n",
    "\n",
    "    # Get the training and testing data for the current crime type\n",
    "    y_train_crime = y_train[crime_type]\n",
    "    y_test_crime = y_test[crime_type]\n",
    "\n",
    "    # Train Decision Tree Regressor model\n",
    "    model = DecisionTreeRegressor(random_state=42)\n",
    "    model.fit(x_train, y_train_crime)\n",
    "\n",
    "    # Predict on training and testing sets\n",
    "    y_train_pred = model.predict(x_train)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "\n",
    "    # Plot the actual vs predicted values\n",
    "    ax[row, col].scatter(x_train['Year'], y_train_crime, color='blue', label='Actual (Train)', alpha=0.6)\n",
    "    ax[row, col].scatter(x_test['Year'], y_test_crime, color='green', label='Actual (Test)', alpha=0.6)\n",
    "    ax[row, col].plot(x_train['Year'], y_train_pred, color='red', linewidth=2, label='Predicted (Train)')\n",
    "    ax[row, col].plot(x_test['Year'], y_test_pred, color='orange', linewidth=2, label='Predicted (Test)')\n",
    "    \n",
    "    # Set plot titles and labels\n",
    "    ax[row, col].set_title(crime_type)\n",
    "    ax[row, col].set_xlabel('Year')\n",
    "    ax[row, col].set_ylabel('Cases')\n",
    "    ax[row, col].legend()\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\", \n",
    "            \"Assault against women\", \n",
    "            \"Assault against modesty of women\", \"Domestic violence\", \n",
    "            \"Women Trafficking\"]\n",
    "# Define number of folds for K-Fold Cross Validation\n",
    "kfold = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Initialize a dictionary to store the average MSE for each crime type\n",
    "avg_mse = {crime_type: [] for crime_type in crime_types}\n",
    "\n",
    "# Perform K-Fold Cross Validation\n",
    "for crime_type in crime_types:\n",
    "    mse_list = []\n",
    "    \n",
    "    # Iterate through the folds\n",
    "    for train_index, test_index in kfold.split(x):\n",
    "        # Split the data into training and testing sets for the current fold\n",
    "        x_train_fold, x_test_fold = x.iloc[train_index], x.iloc[test_index]\n",
    "        y_train_fold, y_test_fold = y[crime_type].iloc[train_index], y[crime_type].iloc[test_index]\n",
    "        \n",
    "        # Train Decision Tree Regressor model on current fold\n",
    "        model = DecisionTreeRegressor(random_state=42)\n",
    "        model.fit(x_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on the test set of the current fold\n",
    "        y_test_pred_fold = model.predict(x_test_fold)\n",
    "        \n",
    "        # Compute MSE for the current fold\n",
    "        mse = mean_squared_error(y_test_fold, y_test_pred_fold)\n",
    "        mse_list.append(mse)\n",
    "    \n",
    "    # Store the average MSE for the current crime type\n",
    "    avg_mse[crime_type] = np.mean(mse_list)\n",
    "\n",
    "# Print the average MSE for each crime type\n",
    "for crime_type, mse_value in avg_mse.items():\n",
    "    print(f\"Average MSE for {crime_type}: {mse_value/10e7:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming tf_1 is your dataframe\n",
    "crime_types = [\"Rape\", \"Kidnap And Assault\", \"Dowry Deaths\",\n",
    "               \"Assault against women\", \"Assault against modesty of women\",\n",
    "               \"Domestic violence\", \"Women Trafficking\", \"Total\"]\n",
    "\n",
    "def time_series_cv(data, n_splits=5):\n",
    "    n = len(data)\n",
    "    k = n // n_splits\n",
    "    for i in range(n_splits):\n",
    "        train = data.iloc[:n - (i+1)*k]\n",
    "        test = data.iloc[n - (i+1)*k:n - i*k]\n",
    "        yield train, test\n",
    "\n",
    "mse_scores = {crime_type: [] for crime_type in crime_types}\n",
    "\n",
    "for crime_type in crime_types:\n",
    "    y = tf_1[[\"Year\", crime_type]].set_index(\"Year\")\n",
    "    \n",
    "    for train, test in time_series_cv(y):\n",
    "        model = ARIMA(train, order=(1, 1, 1))\n",
    "        model_fit = model.fit()\n",
    "        \n",
    "        forecast = model_fit.forecast(steps=len(test))\n",
    "        mse = mean_squared_error(test, forecast)\n",
    "        mse_scores[crime_type].append(mse/10e7)\n",
    "\n",
    "print(\"Average MSE scores:\")\n",
    "for crime_type, scores in mse_scores.items():\n",
    "    avg_mse = np.mean(scores)\n",
    "    print(f\"{crime_type}: {avg_mse:.2f}e+07\")\n",
    "\n",
    "print(\"\\nMSE scores for each fold:\")\n",
    "for crime_type, scores in mse_scores.items():\n",
    "    print(f\"\\n{crime_type}:\")\n",
    "    for i, score in enumerate(scores, 1):\n",
    "        print(f\"  Fold {i}: {score:.2f}e+07\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "MLDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
